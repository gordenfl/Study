# Resolve Problem and Challenge

1. Tell me about a difficult bug you fixed. 难解决的bug

* Game 随机问题的出现,但是没有很好的log支撑
    S - Situation
    While in the real-time game development, we started receiving some error log report from product env. it's about the states change randomly in the battle session. The log does not show enough info to lets reproduce. It's random.
    T - Task
    As the backend engineer, it's my responsibility to identify the reason about this bug. and fix it as soon as possible.

    A - Action
    First, I analyzed the log across multi-server and notice that disconnects happened when players were moving and fight a lot of times in a short period.

    I add extra log and collect UPD package. After auto simulating a lot of time. we can reproduce this error happen. Through the log I added I find that the problem is cause the UDP package is not full package. it was truncated.

    After that, I rewrote the package generate logic and I also add a verify logic for that. then make a test on the simulate env. it does not happen again.

    R - Result
    After deploying the patch, the disconnection rate drop by over 90%. The fix also improved the experience in every kinds of network env. It told me that, while the data you packaged you must have a verify logic for it. keep the logic stable.

* Share Creators
    S - Situation
    While Sharecreators we implement the AI based on stablediffusion. The resource module sent request to our AI module with Kafka. alway we can received the full request, but some times our stablediffusion can ignore the package resource module send.
    T - Task
    Because this is very important function in our platform. I need to keep our system stable. I need resolved this as soon as possible.

    A - Action
    I analyze all the log while this problem occur. And the AI module also can received all the message from KAFKA. but the task is disappeared without any other reason. We check our AI Script, we find sometimes we call the AI, send all the description into stablediffusion. It will cause the GPU Overload.

    With analyze the stablediffusion code, I just read a lot of article in the website, then I find that the problem is a task management. We should not send request to stablediffision while the GPU with overload status. Then I implement a distributer worker to send task to the GPUs only not overloaded. all the request was safe to execute.

    R - Result
    After we fix this problem. our system becomes stable. User feedback improved.
    It was challenging but it let me learned a lot of how does stablediffusion works, and basic knowledge of AI.

2. Describe a technical problem you solved creatively. 有创造性的解决问题

* Game product
    S - Situation
    In the multi-player game project, We need real-time player rankings data leaderboard. that will show to players across different regions. However our infrastructure does not support that. And we don't have so much cost to buy distribution database cluster to support.

    T - Task
    I am a backend engineer. I had to design and implement a scalable, low-latency leaderboard system. It should handle millions of players. then only show Top-N rank in real time.

    A - Action
    I have an idea to using NON-SQL just Redis' ZSET to help us. because ZSET is a sorted set.
    * each region have its own redis. I set player ids is the members and scores is the values
    * I use ZINCRBY to update, because it's atomic. 原子化操作
    * For memory efficiency, I compressed the data and cache only 1000 players
    * To resolve the "Clod start" I just use "Hybrid Storage": data is older than 7 days were flushed into a RDS achieved. and the background job refreshed Redis daily for that.
    * using RESTfull API for querying different ranks AND top of global players. And add batch data writer to delayed-write from Redis to RDS async.

    R - Result
    This design is served over 10million users, 99% of latency of under 50ms, and cost becomes less than $100/month. It was stable even during peak traffic.

* Share Creator
    S - Situation
    Our product has a performance issue: the AI generate picture with words description is too slow, because it will using the GPU and has a very long time to generate on that.

    T - Task
    As a experienced backend engineer I need to optimize that make it more efficiency. I just read some article about the Stablediffusion and AI system.

    A - Action
    Instead to send request directly to GPU, I decide to add some argument into the request. Some people always want to see the description is right or not. the request is just a test, not a real generation.
    I just design a level for each request, default is low accuracy(精度), and if you need get real picture as your words description, just choose the hight accuracy to AI system. It can reduce GPU's load.

    R - Result
    After that improvement, the GPU does not so busy, and we reduced a lot of GPU spend. cost is reduced as well.

3. Tell me about a time when something broke in production. What did you do? 


* Game Product  就是升级以后对于一种技能不存在分数的时候用一个default值来补充,如果没有这个值就会导致卡在matching中.然后我就更新代码让这个值有一个default value, 然后将现在线上所有的玩家数据都更新一遍,让他们能够正常工作,这件事情以后更新了整个流程,让以后类似的事情都不在发生.
    S - Situation
    As a online multiplayer games*, we have a very important function that is matchmaking system. Sometime player started reporting that they just stuck on the "Find Match...." screen. Could not enter into game.

    T - Task
    As the on-call engineer, and one of the core contributors to the matching service, I need to identify the root cause, fix the bug quickly.

    A - Action
    First I checked the matching logs and system health log. I find that some worker in Matchmaker service was still receiving requests but not generate the game session. The matchmaking throw exception and skip these players request. That means the process does not have right logic.
    To fix that:
    * I try to revert this logic code to previous version through blue-green deployment switch.
    * Then create a hotfix to add a default skill score for players
    * Change matching condition to using the default skill score for each player, if the player does not have skill score.
    * Finally, I updated the online user's data while the user does not have that skill score. 更新了服务器上已经存在 卡住的玩家上的信息,让他们能够正确

    R - Result
    After the update, matchmaking system can provide the normal service. After the incident, I add a backward-compatible validation step to our release pipeline. It helps avoid another kinds of problem such like this occur again.

* Share Creators
    S - Situation
    After publish the function of AI generation. we received a lot of warning report from the API response time even some of them timeout.
    T - Target
    As the lead of the whole engineer team. I was responsible for fix that issue. recover the service available and identifying the root reason of this problem.

    A - Action
    I started by looking into our system management tool and saw that our endpoint latency had jumped from 200ms to 3 seconds, and the CPU usage also increase at that time.
    After that, I found new deploy feature add a optional query parameter to that function. but the SQL query does not add this optimized logic. And it cause table scan on 10Million rows of that table, become so slow.
    We need fix this:
    * immediately rolled back this deployment to stop the pressure
    * Collaborate with the developer who response for this change, we change the logic to use indexes and limit result size.
    * Added a conditional logic to skip joins. only permitted the logic who need that.
    * Create new Test case to this logic

    R - Result
    After that we re-deployed the optimized version the service becomes normal. the warning report disappeared. This problem let's add performance check in our CI pipeline

4. Describe a performance issue you diagnosed and fixed.

* Game product
    S - Situation
    In our product of real-time game server, we noticed a sharp drop in server tick rate. and the latency during peek hours especial in larger PvP part. Players reported that movement and combat felt laggy.

    T - Task
    As the leader of Game server group. I just make a server-side simulation. my goal is to analyze the bottleneck of our server. and keep our frame rate recover to 50ms.
    
    A - Action
    profiling the server both on the engine(C++) and logic(Python). we find that when the PvP logic execute, we will create a lot of thread to deal with each fighting object, but we find that the player state sync logic performant reduce 60% of  tick time when there are 20+ player in one battlefield. 
    What I did:
    * Rerote ther serialization of the data we sync to each client. 
    * Using a priority-queue to manage the players status update package.
    * Moved all of real-time status work from Threading to async. I make a research of the Threading model we used, it's very low efficient then async. So we change the Multi-Thread model to async

    R - Result
    After update, tick time from 120+ to drop to 35. And this reduced input delay 90% and improved combat experience while multi-player fighting together.
    After that we extend this module of priority-queue to another part and don't use Python Threading anymore.
    